# 常用的机器学习&数据挖掘知识点 

## Basis(基础)：

1. MSE(Mean Square Error 均方误差)，
2. LMS(LeastMean Square 最小均方)，
3. LSM(Least Square Methods 最小二乘法)，
4. MLE(MaximumLikelihood Estimation最大似然估计)，
5. QP(Quadratic Programming 二次规划)， 
6. CP(Conditional Probability条件概率)，
7. JP(Joint Probability 联合概率)，
8. MP(Marginal Probability边缘概率)，
9. Bayesian Formula(贝叶斯公式)，
10. L1 /L2Regularization(L1/L2正则，以及更多的，现在比较火的L2.5正则等)
11. GD(GradientDescent 梯度下降)，
12. SGD(Stochastic Gradient Descent 随机梯度下降)，
13. Eigenvalue(特征值)，
14. Eigenvector(特征向量)，
15. QR-decomposition(QR分解)，
16. Quantile (分位数)，
17. Covariance(协方差矩阵)。



## Common Distribution(常见分布)：



* Discrete Distribution(离散型分布)：
    1. BernoulliDistribution/Binomial(贝努利分布/二项分布)，
    2. Negative BinomialDistribution(负二项分布)，
    3. MultinomialDistribution(多项式分布)，
    4. Geometric Distribution(几何分布)，
    5. HypergeometricDistribution(超几何分布)，
    6. Poisson Distribution (泊松分布)

* Continuous Distribution (连续型分布)：
    1. UniformDistribution(均匀分布)，
    2. Normal Distribution /Guassian Distribution(正态分布/高斯分布)，ExponentialDistribution(指数分布)，
    3. Lognormal Distribution(对数正态分布)，
    4. GammaDistribution(Gamma分布)，
    5. Beta Distribution(Beta分布)，
    6. Dirichlet Distribution(狄利克雷分布)，
    7. Rayleigh Distribution(瑞利分布)，
    8. Cauchy Distribution(柯西分布)，
    9. Weibull Distribution (韦伯分布)


* Three Sampling Distribution(三大抽样分布)：
    1. Chi-squareDistribution(卡方分布)，
    2. t-distribution(t-distribution)，
    3. F-distribution(F-分布)



## Data Pre-processing(数据预处理)：

1. Missing Value Imputation(缺失值填充)，
2. Discretization(离散化)，
3. Mapping(映射)，
4. Normalization(归一化/标准化)。



## Sampling(采样)：

1. Simple Random Sampling(简单随机采样)，
2. OfflineSampling(离线等可能K采样)，
3. Online Sampling(在线等可能K采样)，
4. Ratio-based Sampling(等比例随机采样)，
5. Acceptance-RejectionSampling(接受-拒绝采样)，
6. Importance Sampling(重要性采样)，
7. MCMC(MarkovChain Monte Carlo 马尔科夫蒙特卡罗采样算法：Metropolis-Hasting& Gibbs)。

## Clustering(聚类)：

1. K-Means，
2. K-Mediods，
3. 二分K-Means，
4. FK-Means，
5. Canopy，
6. Spectral-KMeans(谱聚类)，
7. GMM-EM(混合高斯模型-期望最大化算法解决)，
8. K-Pototypes，
9. CLARANS(基于划分)，
1. BIRCH(基于层次)，
2. CURE(基于层次)，
3. DBSCAN(基于密度)，
4. CLIQUE(基于密度和基于网格)



## Classification&Regression(分类&回归)：

1. LR(Linear Regression 线性回归)，
2. LR(LogisticRegression逻辑回归)，
3. SR(Softmax Regression 多分类逻辑回归)，GLM(GeneralizedLinear Model 广义线性模型)，
4. RR(Ridge Regression 岭回归/L2正则最小二乘回归)，LASSO(Least Absolute Shrinkage andSelectionator Operator L1正则最小二乘回归)， 
5. RF(随机森林)，
6. DT(DecisionTree决策树)，
7. GBDT(Gradient BoostingDecision Tree 梯度下降决策树)，CART(ClassificationAnd Regression Tree 分类回归树)，
8. KNN(K-Nearest Neighbor K近邻)，
9. SVM(Support VectorMachine)，
10. KF(Kernel Function 核函数 Polynomial Kernel Function 多项式核函数、Guassian KernelFunction 高斯核函数/Radial BasisFunction RBF径向基函数、String KernelFunction 字符串核函数)、 
11. NB(Naive Bayes 朴素贝叶斯)，
12. BN(Bayesian Network/Bayesian Belief Network/ Belief Network 贝叶斯网络/贝叶斯信度网络/信念网络)，
13. LDA(Linear Discriminant Analysis/FisherLinear Discriminant 线性判别分析/Fisher线性判别)，
14. EL(Ensemble Learning集成学习Boosting，Bagging，Stacking)，
15. AdaBoost(Adaptive Boosting 自适应增强)，MEM(MaximumEntropy Model最大熵模型)



## Effectiveness Evaluation(分类效果评估)：

1. Confusion Matrix(混淆矩阵)，
2. Precision(精确度)，
3. Recall(召回率)，
4. Accuracy(准确率)，
5. F-score(F得分)，
6. ROC Curve(ROC曲线)，
7. AUC(AUC面积)，
8. LiftCurve(Lift曲线) ，
9. KS Curve(KS曲线)。

## PGM(Probabilistic Graphical Models概率图模型)：

1. BN(Bayesian Network/Bayesian Belief Network/ BeliefNetwork 贝叶斯网络/贝叶斯信度网络/信念网络)，
2. MC(Markov Chain 马尔科夫链)，
3. HMM(HiddenMarkov Model 马尔科夫模型)，
4. MEMM(Maximum Entropy Markov Model 最大熵马尔科夫模型)，
5. CRF(ConditionalRandom Field 条件随机场)，
6. MRF(MarkovRandom Field 马尔科夫随机场)。



## NN(Neural Network神经网络)：

1. ANN(Artificial Neural Network 人工神经网络)，
2. BP(Error BackPropagation 误差反向传播)

## Deep Learning(深度学习)：

1. Auto-encoder(自动编码器)，
2. SAE(Stacked Auto-encoders堆叠自动编码器：Sparse Auto-encoders稀疏自动编码器、Denoising Auto-encoders去噪自动编码器、Contractive Auto-encoders 收缩自动编码器)，
3. RBM(RestrictedBoltzmann Machine 受限玻尔兹曼机)，
4. DBN(Deep Belief Network 深度信念网络)，
5. CNN(ConvolutionalNeural Network 卷积神经网络)，
6. Word2Vec(词向量学习模型)。



## DimensionalityReduction(降维)：

1. LDA LinearDiscriminant Analysis/Fisher Linear Discriminant 线性判别分析/Fisher线性判别，
2. PCA(Principal Component Analysis 主成分分析)，
3. ICA(IndependentComponent Analysis 独立成分分析)，
4. SVD(Singular Value Decomposition 奇异值分解)，
5. FA(FactorAnalysis 因子分析法)。

## Text Mining(文本挖掘)：

1. VSM(Vector Space Model向量空间模型)，
2. Word2Vec(词向量学习模型)，
3. TF(Term Frequency词频)，
4. TF-IDF(Term Frequency-Inverse DocumentFrequency 词频-逆向文档频率)，
5. MI(MutualInformation 互信息)，
6. ECE(Expected Cross Entropy 期望交叉熵)，
7. QEMI(二次信息熵)，
8. IG(InformationGain 信息增益)，
9. IGR(Information Gain Ratio 信息增益率)，
10. Gini(基尼系数)，
11. x2 Statistic(x2统计量)，
12. TEW(TextEvidence Weight文本证据权)，
13. OR(Odds Ratio 优势率)，
14. N-Gram Model，
15. LSA(Latent Semantic Analysis 潜在语义分析)，
16. PLSA(ProbabilisticLatent Semantic Analysis 基于概率的潜在语义分析)，
17. LDA(Latent DirichletAllocation 潜在狄利克雷模型)



## Association Mining(关联挖掘)：

1. Apriori，
2. FP-growth(Frequency Pattern Tree Growth 频繁模式树生长算法)，
3. AprioriAll，
4. Spade。


## Recommendation Engine(推荐引擎)：

1. DBR(Demographic-based Recommendation 基于人口统计学的推荐)，
2. CBR(Context-basedRecommendation 基于内容的推荐)，CF(Collaborative Filtering协同过滤)，
3. UCF(User-basedCollaborative Filtering Recommendation 基于用户的协同过滤推荐)，
4. ICF(Item-basedCollaborative Filtering Recommendation 基于项目的协同过滤推荐)。


## Similarity Measure&Distance Measure(相似性与距离度量)：

1. Euclidean Distance(欧式距离)，
2. ManhattanDistance(曼哈顿距离)，
3. Chebyshev Distance(切比雪夫距离)，
4. MinkowskiDistance(闵可夫斯基距离)，
5. Standardized Euclidean Distance(标准化欧氏距离)，
6. MahalanobisDistance(马氏距离)，
7. Cos(Cosine 余弦)，
8. HammingDistance/Edit Distance(汉明距离/编辑距离)，
9. JaccardDistance(杰卡德距离)，
10. Correlation Coefficient Distance(相关系数距离)，
11. InformationEntropy(信息熵)，
12. KL(Kullback-Leibler Divergence KL散度/Relative Entropy 相对熵)。

## Optimization(最优化)：

* Non-constrainedOptimization(无约束优化)：
    1. Cyclic VariableMethods(变量轮换法)，
    2. Pattern Search Methods(模式搜索法)，
    3. VariableSimplex Methods(可变单纯形法)，
    4. Gradient Descent Methods(梯度下降法)，
    5. Newton Methods(牛顿法)，
    6. Quasi-NewtonMethods(拟牛顿法)，
    7. Conjugate Gradient Methods(共轭梯度法)。

* ConstrainedOptimization(有约束优化)：
    1. Approximation Programming Methods(近似规划法)，
    2. FeasibleDirection Methods(可行方向法)，
    3. Penalty Function Methods(罚函数法)，
    4. Multiplier Methods(乘子法)。



Heuristic Algorithm(启发式算法)，SA(SimulatedAnnealing，模拟退火算法)，GA(genetic algorithm遗传算法)



## Feature Selection(特征选择算法)：

1. Mutual Information(互信息)，
2. DocumentFrequence(文档频率)，
3. Information Gain(信息增益)，
4. Chi-squared Test(卡方检验)，
5. Gini(基尼系数)。



## Outlier Detection(异常点检测算法)：

1. Statistic-based(基于统计)，
2. Distance-based(基于距离)，
3. Density-based(基于密度)，
4. Clustering-based(基于聚类)。



## Learning to Rank(基于学习的排序)：

1. Pointwise：McRank；
2. Pairwise：RankingSVM，RankNet，Frank，RankBoost；
3. Listwise：AdaRank，SoftRank，LamdaMART；



## Tool(工具)：

MPI，Hadoop生态圈，Spark，BSP，Weka，Mahout，Scikit-learn，PyBrain…
